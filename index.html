<script src="/app.js"></script>
<script type="text/javascript">
var gk_isXlsx = false;
        var gk_xlsxFileLookup = {};
        var gk_fileData = {};
        function filledCell(cell) {
          return cell !== '' && cell != null;
        }
        function loadFileData(filename) {
        if (gk_isXlsx && gk_xlsxFileLookup[filename]) {
            try {
                var workbook = XLSX.read(gk_fileData[filename], { type: 'base64' });
                var firstSheetName = workbook.SheetNames[0];
                var worksheet = workbook.Sheets[firstSheetName];

                // Convert sheet to JSON to filter blank rows
                var jsonData = XLSX.utils.sheet_to_json(worksheet, { header: 1, blankrows: false, defval: '' });
                // Filter out blank rows (rows where all cells are empty, null, or undefined)
                var filteredData = jsonData.filter(row => row.some(filledCell));

                // Heuristic to find the header row by ignoring rows with fewer filled cells than the next row
                var headerRowIndex = filteredData.findIndex((row, index) =>
                  row.filter(filledCell).length >= filteredData[index + 1]?.filter(filledCell).length
                );
                // Fallback
                if (headerRowIndex === -1 || headerRowIndex > 25) {
                  headerRowIndex = 0;
                }

                // Convert filtered JSON back to CSV
                var csv = XLSX.utils.aoa_to_sheet(filteredData.slice(headerRowIndex)); // Create a new sheet from filtered array of arrays
                csv = XLSX.utils.sheet_to_csv(csv, { header: 1 });
                return csv;
            } catch (e) {
                console.error(e);
                return "";
            }
        }
        return gk_fileData[filename] || "";
        }
     </script><!DOCTYPE html>
   <html lang="en">
   <head>
       <meta charset="UTF-8">
       <meta name="viewport" content="width=device-width, initial-scale=1.0">
       <title>CEFR Reading Test</title>
       <link rel="stylesheet" href="public/styles.css">
   </head>
   <body>
       <h1>CEFR Reading Test</h1>
       <div>
           <label for="sentenceSelect">Choose a sentence to read:</label>
           <select id="sentenceSelect">
               <option value="0">The quick brown fox jumps over the lazy dog. This is a sample text for reading.</option>
               <option value="1">She sells seashells by the seashore.</option>
               <option value="2">Peter Piper picked a peck of pickled peppers.</option>
               <option value="3">A journey of a thousand miles begins with a single step.</option>
           </select>
       </div>
       <div>
           <button id="startBtn">Start Recording</button>
           <button id="stopBtn" disabled>Stop Recording</button>
       </div>
       <div id="status">Ready to record</div>
       <div id="result"></div>
       <script>
           const exemplarFeaturesList = [
               { duration: 7.0, phonemeCount: 45, text: "The quick brown fox jumps over the lazy dog. This is a sample text for reading." },
               { duration: 5.0, phonemeCount: 30, text: "She sells seashells by the seashore." },
               { duration: 6.0, phonemeCount: 35, text: "Peter Piper picked a peck of pickled peppers." },
               { duration: 8.0, phonemeCount: 50, text: "A journey of a thousand miles begins with a single step." }
           ];
           let mediaRecorder, startTime, audioChunks = [], mimeType = 'audio/webm';
           let recognition;

           // Initialize Web Speech API
           const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
           if (SpeechRecognition) {
               recognition = new SpeechRecognition();
               recognition.lang = 'en-US';
               recognition.interimResults = false;
               recognition.maxAlternatives = 1;
           } else {
               console.error('SpeechRecognition API not supported in this browser.');
               document.getElementById('status').textContent = 'Error: Speech recognition not supported. Try Chrome.';
           }

           function calculateFluency(duration, selectedSentenceIndex) {
               const idealDuration = exemplarFeaturesList[selectedSentenceIndex]?.duration || 7;
               console.log('Ideal Duration:', idealDuration, 'Recorded Duration:', duration, 'Sentence Index:', selectedSentenceIndex);
               if (!duration || duration <= 0 || !idealDuration || idealDuration <= 0) {
                   console.log('Invalid duration or idealDuration, returning fallback score');
                   return 0.5;
               }
               const deviation = Math.abs(duration - idealDuration) / idealDuration;
               const score = Math.max(0, 1 - deviation);
               console.log('Fluency score calculated:', score, 'duration:', duration, 'deviation:', deviation);
               return score;
           }
async function comparePhonetics(audioBlob, selectedSentenceIndex) {
    try {
        const reader = new FileReader();
        return new Promise((resolve) => {
            reader.onload = async () => {
                const audioBase64 = reader.result;
                const expectedText = exemplarFeaturesList[selectedSentenceIndex].text;
         const response = await fetch('https://cefr-speech-backend.herokuapp.com/transcribe', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ audio: audioBase64, text: expectedText })
});
                const result = await response.json();
                if (result.error) {
                    console.error('Transcription error:', result.error);
                    return resolve(0.85);
                }
                console.log('Transcription:', result.transcription, 'Accuracy:', result.accuracy, 'Confidence:', result.confidence);
                return resolve(result.accuracy * result.confidence);
            };
            reader.readAsDataURL(audioBlob);
        });
    } catch (error) {
        console.error('Error in comparePhonetics:', error);
        return 0.85;
    }
}
           async function comparePhonetics(audioBlob, selectedSentenceIndex) {
               if (!SpeechRecognition) return 0.85; // Fallback if API unavailable
               return new Promise((resolve) => {
                   recognition.onresult = (event) => {
                       const transcript = event.results[0][0].transcript.toLowerCase().replace(/[.,]/g, '');
                       const expectedText = exemplarFeaturesList[selectedSentenceIndex].text.toLowerCase().replace(/[.,]/g, '');
                       console.log('Transcript:', transcript, 'Expected:', expectedText);
                       const transcriptWords = transcript.split(' ').filter(word => word);
                       const expectedWords = expectedText.split(' ').filter(word => word);
                       let correctWords = 0;
                       for (let i = 0; i < Math.min(transcriptWords.length, expectedWords.length); i++) {
                           if (transcriptWords[i] === expectedWords[i]) correctWords++;
                       }
                       const accuracy = expectedWords.length > 0 ? correctWords / expectedWords.length : 0;
                       console.log('Pronunciation accuracy:', accuracy, 'Correct words:', correctWords, 'Total words:', expectedWords.length);
                       resolve(accuracy);
                   };
                   recognition.onerror = (event) => {
                       console.error('Speech recognition error:', event.error);
                       resolve(0.85); // Fallback
                   };
                   recognition.onend = () => {
                       if (!recognition.result) resolve(0.85); // Fallback if no result
                   };
                   const audioUrl = URL.createObjectURL(audioBlob);
                   const audio = new Audio(audioUrl);
                   const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                   fetch(audioUrl)
                       .then(response => response.arrayBuffer())
                       .then(buffer => audioContext.decodeAudioData(buffer))
                       .then(() => {
                           recognition.start();
                       })
                       .catch(err => {
                           console.error('Audio decode error:', err);
                           resolve(0.85);
                       });
               });
           }

           async function analyzeRecording(audioBlob, duration, selectedSentenceIndex) {
               console.log('Analyzing recording, blob size:', audioBlob.size, 'duration:', duration);
               const fluencyScore = calculateFluency(duration, selectedSentenceIndex);
               const phoneticAccuracy = await comparePhonetics(audioBlob, selectedSentenceIndex);
               return { fluencyScore, phoneticAccuracy, duration };
           }

           function assignCEFRGrade(analysis) {
               const compositeScore = (analysis.fluencyScore * 0.5 + analysis.phoneticAccuracy * 0.5) * 100;
               console.log('Composite Score:', compositeScore);
               if (compositeScore >= 90) return 'C2';
               if (compositeScore >= 80) return 'C1';
               if (compositeScore >= 70) return 'B2';
               if (compositeScore >= 60) return 'B1';
               if (compositeScore >= 50) return 'A2';
               return 'A1';
           }

           function displayResult(grade, analysis) {
               console.log('Displaying result:', analysis, 'Grade:', grade);
               document.getElementById('result').textContent = 
                   `Fluency Score: ${(analysis.fluencyScore * 100).toFixed(1)}%\n` +
                   `CEFR Grade: ${grade}\n` +
                   `Phonetic Accuracy: ${(analysis.phoneticAccuracy * 100).toFixed(1)}%`;
           }

           function resetUI() {
               document.getElementById('startBtn').disabled = false;
               document.getElementById('stopBtn').disabled = true;
               document.getElementById('status').textContent = 'Ready to record';
           }

           async function setupRecording() {
               try {
                   const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                   mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });
                   startTime = Date.now();
                   audioChunks = [];
                   mediaRecorder.ondataavailable = (e) => {
                       if (e.data.size > 0) audioChunks.push(e.data);
                   };
                   mediaRecorder.onstop = async () => {
                       console.log('Recording stopped, processing audio...');
                       const audioBlob = new Blob(audioChunks, { type: mimeType });
                       document.getElementById('status').textContent = 'Processing recording...';
                       let duration = (Date.now() - startTime) / 1000;
                       console.log('Calculated Duration:', duration);
                       if (duration <= 0) {
                           console.log('Invalid duration, using fallback of 7 seconds');
                           duration = 7;
                       }
                       const selectedSentenceIndex = document.getElementById('sentenceSelect').value;
                       const analysis = await analyzeRecording(audioBlob, duration, selectedSentenceIndex);
                       const grade = assignCEFRGrade(analysis);
                       displayResult(grade, analysis);
                       audioChunks = [];
                       resetUI();
                   };
                   if (SpeechRecognition) {
                       recognition.start();
                   }
               } catch (err) {
                   console.error('Error setting up recording:', err.name, err.message);
                   document.getElementById('status').textContent = 'Error: Microphone access was denied. Please allow microphone access in your browser settings.';
               }
           }

           document.getElementById('startBtn').addEventListener('click', () => {
               console.log('Start recording button clicked');
               document.getElementById('startBtn').disabled = true;
               document.getElementById('stopBtn').disabled = false;
               document.getElementById('status').textContent = 'Recording...';
               setupRecording().then(() => mediaRecorder.start());
           });

           document.getElementById('stopBtn').addEventListener('click', () => {
               console.log('Stop recording button clicked');
               mediaRecorder.stop();
               if (SpeechRecognition) recognition.stop();
           });
       </script>
   </body>
   </html>
</html>